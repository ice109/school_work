MAD6406 Homework Fall 2015

1.  Claim: R
 upper triangular and nonsingular iff R^{-1}
 upper 
  triangular.

  R
 nonsingular implies all diagonal entries of R
 are non-zero. 
  Therefore for n<m
 the span of \left\{ r_{1},\dots,r_{n}\right\} 

  , where r_{i}
 are the columns of R
, is \mathbb{R}^{n}
. 
  Therefore there exist \rho_{jn}
 for j=1,\dots,n
 such that r_{1}\rho_{1n}+r_{2}\rho_{2n}+\cdots+r_{n}\rho_{nn}=e_{n}

  Let \rho_{jn}=0
 for n<j<\leq m
 and hence r_{1}\rho_{1n}+r_{2}\rho_{2n}+\cdots+r_{m}\rho_{mn}=e_{n}

  Then let \rho_{i}=\begin{bmatrix}\rho_{1i}\\
\vdots\\
\rho_{ii}\\
\vdots\\
\rho_{mi}
\end{bmatrix}=\begin{bmatrix}\rho_{1i}\\
\vdots\\
\rho_{ii}\\
0\\
\vdots\\
0
\end{bmatrix}

  and P=\begin{bmatrix}\rho_{1} & \cdots & \rho_{m}\end{bmatrix}

  . Note that P
 is upper-triangular since for all i
 it's the 
  case that \rho_{jn}=0
 for j=n+1,\cdots,m
. Furthermore by [eq:uppertriang]
   we have that R\cdot P=I
 and by uniqueness of inverses P=R^{-1}

  . 

2.  Claim: for self-adjoint A\in\mathbb{C}^{m\times m}


  (a) All eigenvalues of A
 are real.

  (b) Eigenvectors corresponding to distinct eigenvalues are 
    orthogonal.

  

    (a) Let x\neq0
 and \lambda
 such that Ax=\lambda x
. Then by 
      self-adjointness\left(x^{\dagger}Ax\right)^{\dagger}=\left(\left(Ax\right)^{\dagger}\left(x^{\dagger}\right)^{\dagger}\right)=\left(x^{\dagger}A^{\dagger}x\right)=\left(x^{\dagger}Ax\right)

      butx^{\dagger}Ax=x^{\dagger}\lambda x=\lambda\left\Vert x\right\Vert ^{2}

      and \lambda\left\Vert x\right\Vert ^{2}=\left(\lambda\left\Vert x\right\Vert ^{2}\right)^{\dagger}=\lambda^{*}\left\Vert x\right\Vert ^{2}

      . Therefore \lambda=\lambda^{*}
 hence \lambda\in\mathbb{R}

      .

    (b) Let x\neq y\neq0
 and \lambda,\lambda^{'}
 such thatAx=\lambda x

       and Ay=\lambda^{'}y
. Then by self-adjointnessx^{\dagger}Ay=\left(Ax\right)^{\dagger}y

      and so since \lambda,\lambda^{'}\in\mathbb{R}
 0=x^{\dagger}Ay-\left(Ax\right)^{\dagger}y=\lambda^{'}x^{\dagger}y-\lambda x^{\dagger}y=\left(\lambda^{'}-\lambda\right)x^{\dagger}y

      Therefore since \lambda\neq\lambda^{'}
 it's the case that \lambda^{'}-\lambda\neq0

       and hence x^{\dagger}y=0
.

3. Claim: \left\Vert A\right\Vert _{F}=\left\Vert uv^{*}\right\Vert _{F}=\left\Vert u\right\Vert _{F}\left\Vert v\right\Vert _{F}

  .

  Since the Frobenius norm of a vector is just the 2-norm so it 
  distributes over the product. To wit if A=uv^{*}
 \left\Vert A\right\Vert _{F}=\left\Vert uv^{*}\right\Vert _{F}=\sqrt{\sum_{i,j}\left|u_{j}v_{i}^{*}\right|^{2}}=\sqrt{\sum_{j}\left|u_{j}\right|^{2}\sum_{i}\left|v_{i}^{*}\right|^{2}}=\sqrt{\sum_{j}\left|u_{j}\right|^{2}}\sqrt{\sum_{i}\left|v_{i}^{*}\right|^{2}}

  Now since \left|x^{*}\right|=\left|x\right|
\sqrt{\sum_{j}\left|u_{j}\right|^{2}}\sqrt{\sum_{i}\left|v_{i}^{*}\right|^{2}}=\sqrt{\sum_{j}\left|u_{j}\right|^{2}}\sqrt{\sum_{i}\left|v_{i}\right|^{2}}=\left\Vert u\right\Vert _{F}\left\Vert v\right\Vert _{F}


4. Claim: it is false that A,B\in\mathbb{C}^{m}
 are unitary 
  equivalent iff they have the same singular values.

  A
 and -A
 have the same singular values: let A=U\Sigma V^{-1}

  , then -A=U\Sigma\left(-V^{-1}\right)
But A
 and -A
 cannot be 
  unitarily equivalent since then \det\left(A\right)	=	\det\left(Q\left(-A\right)Q^{-1}\right)
	=	\det\left(Q\right)\det\left(-A\right)\det\left(Q^{-1}\right)
	=	\det\left(Q\right)\det\left(Q^{-1}\right)\det\left(-A\right)
	=	\left(-1\right)^{m}\det\left(A\right)

  which is only true if m
 is even or \det\left(A\right)=0
. 
  Alternatively \text{tr}\left(A\right)	=	\text{tr}\left(Q\left(-A\right)Q^{-1}\right)
	=	\text{tr}\left(Q^{-1}Q\left(-A\right)\right)
	=	-\text{tr}\left(A\right)

  which is only true if \left(A\right)_{ii}=0
 for all i
.

5. Claim: if A\in\mathbb{C}^{m\times m}
, with A=U\Sigma V^{-1}=U\Sigma V^{\dagger}

  , and B=\begin{pmatrix}0 & A^{\dagger}\\
A & 0
\end{pmatrix}

  then there exists X,\Lambda
 such that B=X\Lambda X^{-1}
 is an 
  eigenvalue decomposition.

  First note that A^{\dagger}=\left(U\Sigma V^{\dagger}\right)^{\dagger}=V\Sigma^{\dagger}U^{\dagger}=V\Sigma U^{\dagger}

   since singular values are always real[footnote:
Thm. 4.1 in Trefethen: \sigma_{1}=\left\Vert A\right\Vert 

]. Since A
 is square A^{\dagger}u_{j}	=	\sigma_{j}v_{j}
Av_{j}	=	\sigma_{j}u_{j}

  Hence B\begin{pmatrix}u_{j}\\
v_{j}
\end{pmatrix}=\begin{pmatrix}0 & A^{\dagger}\\
A & 0
\end{pmatrix}\begin{pmatrix}v_{j}\\
u_{j}
\end{pmatrix}=\begin{pmatrix}A^{\dagger}u_{j}\\
Av_{j}
\end{pmatrix}=\begin{pmatrix}\sigma_{j}v_{j}\\
\sigma_{j}u_{j}
\end{pmatrix}=\sigma_{j}\begin{pmatrix}v_{j}\\
u_{j}
\end{pmatrix}

  and B\begin{pmatrix}v_{j}\\
-u_{j}
\end{pmatrix}=\begin{pmatrix}0 & A^{\dagger}\\
A & 0
\end{pmatrix}\begin{pmatrix}v_{j}\\
-u_{j}
\end{pmatrix}=\begin{pmatrix}-A^{\dagger}u_{j}\\
Av_{j}
\end{pmatrix}=\begin{pmatrix}-\sigma_{j}v_{j}\\
\sigma_{j}u_{j}
\end{pmatrix}=-\sigma_{j}\begin{pmatrix}v_{j}\\
-u_{j}
\end{pmatrix}

  Therefore the eigenvectors of B
 are \left\{ \begin{pmatrix}v_{1}\\
u_{1}
\end{pmatrix},\dots,\begin{pmatrix}v_{m}\\
u_{m}
\end{pmatrix},\begin{pmatrix}v_{1}\\
-u_{1}
\end{pmatrix},\dots,\begin{pmatrix}v_{m}\\
-u_{m}
\end{pmatrix}\right\} 

   with eigenvalues \left\{ \sigma_{1},\dots,\sigma_{m},-\sigma_{1},\dots,-\sigma_{m}\right\} 

   and hence B=\begin{pmatrix}V & V\\
U & -U
\end{pmatrix}\begin{pmatrix}\Sigma & 0\\
0 & -\Sigma
\end{pmatrix}\begin{pmatrix}V & V\\
U & -U
\end{pmatrix}^{-1}


6. Claim: if P
 is an orthogonal projector, the I-2P
 is unitary.

  Since P
 is an orthogonal projector P=P^{\dagger}
 and hence \left(I-2P\right)^{\dagger}\left(I-2P\right)	=	\left(I^{\dagger}-2P^{\dagger}\right)\left(I-2P\right)
	=	\left(I-2P\right)\left(I-2P\right)
	=	I-4P-4P^{2}
	=	I-4P-4P
	=	I

  Hence P
 is unitary. The geometric intuition is that since I-2P=\left(I-P\right)-P

   it's the case that \left(I-2P\right)x	=	\left(I-P\right)x-Px

  Since in general x=\left(I-P\right)x+Px
 it's obvious that \left(I-P\right)x+\left(-Px\right)

   is the reflection of x
 across \text{range}\left(I-P\right)
, 
  which is what unitary transformations are (reflections and/or 
  rotations).

7. Let P_{1}=\left[x^{\left(1\right)},y^{\left(1\right)}\right]
 
  and P_{2}=\left[x^{\left(2\right)},y^{\left(2\right)}\right]
 
  be matrices. Then compute the full QR factorizations P_{1}=Q_{1}R_{1}

   and P_{2}=Q_{2}R_{2}
. The third columns z^{\left(1\right)},z^{\left(2\right)}

  of Q_{1},Q_{2}
 are orthogonal to P^{\left(1\right)},P^{\left(2\right)}

   respectively. Then let matrix P_{3}=\left[z^{\left(1\right)},z^{\left(2\right)}\right]

   and P_{3}=Q_{3}R_{3}
. Then the third column z^{\left(3\right)}

   of Q_{3}
 is orthogonal to \left\langle z^{\left(1\right)},z^{\left(2\right)}\right\rangle 

  , i.e. in both P^{\left(1\right)}
 and P^{\left(2\right)}
.




8. QR factorization in MATLABfunction [ Q,R ] = mgs( A )



n=size(A,2); 

V = A; 

R = zeros(n); 

Q = zeros(size(A));

for i=1:n

    R(i,i) = norm(V(:,i));

    Q(:,i) = V(:,i)/R(i,i);

    for j=i+1:n

        R(i,j) = dot(conj(Q(:,i)),V(:,j));

        V(:,j) = V(:,j) - R(i,j)*Q(:,i);

    end

end

9. 

  (a) QR factorization by Householder orthogonal 
    triangularization in MATLABfunction [W,R] = house( A )

%HOUSE computes implicit representation of QR using householder

%orthogonal trianglurization

[m,n]=size(A);

W=zeros([m,n]);

R=A;

for k=1:n

    x = R(k:m,k);

    vk = sign(x(1))*norm(x)*vertcat(1,zeros(m-k,1)) + x;

    vk = vk/norm(vk);

    W(k:m,k) = vk;

    R(k:m,k:n) = R(k:m,k:n) - 2*vk*(vk'*R(k:m,k:n));

end

end

  (b) Reconstruction of Q from Householder decompositionfunction Q=formQ(W)

%formQ reconstructs Q from W by computing Qe_i for i=1,..,m

[m,n]=size(W);

Q=eye(m);

for j=1:m

    for k=n:-1:1

        Q(k:m,j) = Q(k:m,j) - 2*W(k:m,k)*(W(k:m,k)'*Q(k:m,j));

    end

end

end

