{
 "metadata": {
  "name": "ml_test (2)"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn import linear_model, cross_validation\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "cd ~/Desktop/school_work/spring2015/machine_learning/proj_2/data/",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "/home/maksim/Desktop/school_work/spring2015/machine_learning/proj_2/data\n"
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Load data"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "### regression\nyacht_data = np.loadtxt('yacht_hydrodynamics.data')\nparkinsons_tel_data = np.loadtxt('parkinsons_updrs.data',delimiter=',')\n\n# stupid fuckin char columns\nfmts = zip([str(i) for i in range(0,13)],['f8',]*13)\nfmts[2],fmts[3] = ('2','S25'),('3','S25')                    \nforestfires_data = np.genfromtxt('forestfires.data',delimiter=',',dtype=fmts)\n# read file and hash\nforestfires_data = forestfires_data.view((float, len(forestfires_data.dtype.names)))\n\n###classification\nkwargs = dict(delimiter=',',missing_values='?',filling_values=0)\nbreast_cancer_data = np.genfromtxt('breast-cancer-wisconsin.data',**kwargs)\noptical_digits_data = np.loadtxt('optic_digits.data',delimiter=',')\n#bank_note_data = np.loadtxt('bank_note.data')\n#climate_data = np.loadtxt('climate.data')\n\n#char columns\n#ddtype=[('1', 'S10'), ('2', 'f8'), ('3', 'f8'),('4', 'f8'), ('5', 'f8'),('6', 'f8'),  ('7', 'f8'),('8', 'f8'),('9', 'S25')]\nddtype=[('1', 'f8'), ('2', 'f8'), ('3', 'f8'),('4', 'f8'), ('5', 'f8'),('6', 'f8'),  ('7', 'f8'),('8', 'f8'),('9', 'f8')]\necoli_data = np.genfromtxt('ecoli.data',dtype=ddtype, converters={0: converthashfunc, 8: converthashfunc})\n#ecoli_data = ecoli_data.view((float, len(ecoli_data.dtype.names)))\n#ecoli_data = [ [y for y in x ] for x in ecoli_data ]",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 265
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Cross-validation split"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "ecoli_data[0]",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 266,
       "text": "(64592352.0, 0.49, 0.29, 0.48, 0.5, 0.56, 0.24, 0.35, 31114267.0)"
      }
     ],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "forestfires_data[0]",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 246,
       "text": "(7.0, 5.0, '6291', '678', 86.2, 26.2, 94.3, 5.1, 8.2, 51.0, 6.7, 0.0, 0.0)"
      }
     ],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "a = forestfires_data.tolist()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "a = [ [ x for x in y ] for y in a ]",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "np.array(['a',1],dtype=np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))]))",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "expected a readable buffer object",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-229-5520a33bf91b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'grades'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: expected a readable buffer object"
       ]
      }
     ],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "### regression ###\nyacht_train_feat, yacht_test_feat, yacht_train_target, yacht_test_target = cross_validation.train_test_split(\n    yacht_data[:,:-1], yacht_data[:,-1], test_size=0.8, random_state=0)\n#what the hell is the response here???\npark_train_feat, park_test_feat, park_train_target, park_test_target = cross_validation.train_test_split(\n    parkinsons_tel_data[1:,:-1], parkinsons_tel_data[1:,-1], test_size=0.8, random_state=0)\n#response is biased to 0 so maybe take log or last entry?\nforest_train_feat, forest_test_feat, forest_train_target, forest_test_target = cross_validation.train_test_split(\n    forestfires_data[:,:-1], forestfires_data[:,-1], test_size=0.8, random_state=0)\n\n### classification ###\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "list indices must be integers, not tuple",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-159-0c19bf6a3861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#response is biased to 0 so maybe take log or last entry?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m forest_train_feat, forest_test_feat, forest_train_target, forest_test_target = cross_validation.train_test_split(\n\u001b[0;32m----> 9\u001b[0;31m     forestfires_data[:,:-1], forestfires_data[:,-1], test_size=0.8, random_state=0)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m### classification ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: list indices must be integers, not tuple"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regr = linear_model.LinearRegression()\nregr.fit(train_feat,train_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regr.coef_",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": "array([   1.29713236,   54.59046013,   20.92226694,  -11.6771767 ,\n        -29.21019669,  122.72947151])"
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regr.score(test_feat,test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": "0.59552044256423797"
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "bls = linear_model.BayesianRidge(compute_score=True)\nbls.fit(train_feat,train_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=True, copy_X=True,\n       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n       normalize=False, tol=0.001, verbose=False)"
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "bls.score(test_feat,test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": "-0.0022520773431056185"
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "bls.predict(test_feat[2]),test_target[2]",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": "(9.9060294400554625, 47.130000000000003)"
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "sgd = linear_model.SGDRegressor()\nsgd.fit(train_feat,train_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": "SGDRegressor(alpha=0.0001, epsilon=0.1, eta0=0.01, fit_intercept=True,\n       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n       n_iter=5, penalty='l2', power_t=0.25, random_state=None, rho=None,\n       shuffle=False, verbose=0, warm_start=False)"
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "sgd.score(test_feat,test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": "-0.016093040943324866"
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "ridgecv = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\nridgecv.fit(train_feat,train_target)\nridgecv.score(test_feat,test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": "0.60270351867146332"
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Plot true weights, estimated weights and histogram of the weights\nplt.figure(figsize=(6, 5))\nplt.title(\"Weights of the model\")\nplt.plot(bls.coef_, 'b-', label=\"Bayesian Ridge estimate\")\nplt.plot(regr.coef_, 'r--', label=\"OLS estimate\")\nplt.plot(sgd.coef_, 'g-', label=\"SGD estimate\")\nplt.xlabel(\"Features\")\nplt.ylabel(\"Values of the weights\")\nplt.legend(loc=\"best\", prop=dict(size=12))\n'''\nplt.figure(figsize=(6, 5))\nplt.title(\"Histogram of the weights\")\nplt.hist(bls.coef_, bins=6, log=True)\nplt.plot(bls.coef_[relevant_features], 5 * np.ones(len(relevant_features)),\n         'ro', label=\"Relevant features\")\nplt.ylabel(\"Features\")\nplt.xlabel(\"Values of the weights\")\nplt.legend(loc=\"lower left\")\n\nplt.figure(figsize=(6, 5))\nplt.title(\"Marginal log-likelihood\")\nplt.plot(clf.scores_)\nplt.ylabel(\"Score\")\nplt.xlabel(\"Iterations\")'''\nplt.show()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "###############################################################################\n# Compute paths\n\nn_alphas = 200\nalphas = np.logspace(-10, -2, n_alphas)\nclf = linear_model.Ridge(fit_intercept=False)\n\ncoefs = []\nfor a in alphas:\n    clf.set_params(alpha=a)\n    clf.fit(test_feat, test_target)\n    coefs.append(clf.coef_)\n\n###############################################################################\n# Display results\n\nax = plt.gca()\nax.set_color_cycle(['b', 'r', 'g', 'c', 'k', 'y', 'm'])\n\nax.plot(alphas, coefs)\nax.set_xscale('log')\nax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\nplt.xlabel('alpha')\nplt.ylabel('weights')\nplt.title('Ridge coefficients as a function of the regularization')\nplt.axis('tight')\nplt.show()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": "0.60270351867145489"
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "ridgecv.alpha_",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": "0.10000000000000001"
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}