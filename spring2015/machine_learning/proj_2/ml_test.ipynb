{
 "metadata": {
  "name": "ml_test"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn import linear_model, cross_validation, svm, tree, neighbors\nfrom sklearn.lda import LDA\nfrom sklearn.naive_bayes import GaussianNB\nimport statsmodels.api as sm",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "cd ~/Desktop/school_work/spring2015/machine_learning/proj_2/data/",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "/home/maksim/Desktop/school_work/spring2015/machine_learning/proj_2/data\n"
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Load data"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "### regression\nyacht_data = np.loadtxt('yacht_hydrodynamics.data')\nparkinsons_tel_data = np.loadtxt('parkinsons_updrs.data',delimiter=',')\n\n# stupid fuckin char columns\nunique_m = {'apr':1.0, 'aug':2.0, 'dec':3.0, 'feb':4.0, 'jan':5.0, 'jul':6.0, \n            'jun':7.0, 'mar':8.0, 'may':9.0, 'nov':10.0, 'oct':11.0, 'sep':12.0}\nunique_d = {'fri':1.0, 'mon':2.0, 'sat':3.0, 'sun':4.0, 'thu':5.0, 'tue':6.0, 'wed':7.0}\nforestfires_data = np.genfromtxt('forestfires.data',delimiter=','\n                                 , converters={2: lambda x: unique_m[x], 3: lambda x: unique_d[x]})\n\n### classification\nkwargs = dict(delimiter=',',missing_values='?',filling_values=0, usecols=(1,2,3,4,5,6,7,8,9,10))\nbreast_cancer_data = np.genfromtxt('breast-cancer-wisconsin.data',**kwargs)\noptical_digits_data = np.loadtxt('optic_digits.data',delimiter=',')\nbank_note_data = np.genfromtxt('banknote.data',delimiter=',')\nclimate_data = np.loadtxt('climate.data')\n\n# stupid fuckin char columns\nunique_ec = {'cp':1.0, 'im':2.0, 'imL':3.0, 'imS':4.0, 'imU':5.0, 'om':6.0, 'omL':7.0, 'pp':8.0}\nfmts = zip([str(i) for i in range(0,13)],['f8',]*9)\necoli_data = np.genfromtxt('ecoli.data',usecols=(1,2,3,4,5,6,7,8), converters={8: lambda x: unique_ec[x]})\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Cross-validation split"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "### regression ###\nyacht_train_feat, yacht_test_feat, yacht_train_target, yacht_test_target = cross_validation.train_test_split(\n    yacht_data[:,:-1], yacht_data[:,-1], test_size=0.8, random_state=0)\n#what the hell is the response herejQuery202020918934624549046_1428111902664?\npark_train_feat, park_test_feat, park_train_target, park_test_target = cross_validation.train_test_split(\n    parkinsons_tel_data[1:,:-1], parkinsons_tel_data[1:,-1], test_size=0.8, random_state=0)\n#response is biased to 0 so maybe take log or last entry?\nforest_train_feat, forest_test_feat, forest_train_target, forest_test_target = cross_validation.train_test_split(\n    forestfires_data[:,:-1], forestfires_data[:,-1], test_size=0.8, random_state=0)\n\n### classification ###\nbreast_train_feat, breast_test_feat, breast_train_target, breast_test_target = cross_validation.train_test_split(\n    breast_cancer_data[:,:-1], breast_cancer_data[:,-1], test_size=0.8, random_state=0)\noptical_train_feat, optical_test_feat, optical_train_target, optical_test_target = cross_validation.train_test_split(\n    optical_digits_data[:,:-1], optical_digits_data[:,-1], test_size=0.8, random_state=0)\nbank_train_feat, bank_test_feat, bank_train_target, bank_test_target = cross_validation.train_test_split(\n    bank_note_data[:,:-1], bank_note_data[:,-1], test_size=0.8, random_state=0)\nclimate_train_feat, climate_test_feat, climate_train_target, climate_test_target = cross_validation.train_test_split(\n    climate_data[:,:-1], climate_data[:,-1], test_size=0.8, random_state=0)\necoli_train_feat, ecoli_test_feat, ecoli_train_target, ecoli_test_target = cross_validation.train_test_split(\n    ecoli_data[:,:-1], ecoli_data[:,-1], test_size=0.8, random_state=0)\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Linear Regression"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Yacht Hydrodynamics"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.OLS(yacht_train_target, yacht_train_feat)\nresults = model.fit()\nprint(results.summary())",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.818\nModel:                            OLS   Adj. R-squared:                  0.798\nMethod:                 Least Squares   F-statistic:                     41.10\nDate:                Sat, 04 Apr 2015   Prob (F-statistic):           1.36e-18\nTime:                        14:33:04   Log-Likelihood:                -210.69\nNo. Observations:                  61   AIC:                             433.4\nDf Residuals:                      55   BIC:                             446.1\nDf Model:                           6                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nx1             1.3533      0.701      1.931      0.059        -0.051     2.758\nx2            44.8390     35.955      1.247      0.218       -27.217   116.895\nx3            19.4518     16.006      1.215      0.229       -12.626    51.529\nx4           -11.7549      6.574     -1.788      0.079       -24.930     1.420\nx5           -28.8562     19.158     -1.506      0.138       -67.249     9.537\nx6           123.8720     10.645     11.636      0.000       102.539   145.205\n==============================================================================\nOmnibus:                       19.230   Durbin-Watson:                   1.977\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               26.373\nSkew:                           1.208   Prob(JB):                     1.88e-06\nKurtosis:                       5.130   Cond. No.                         291.\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Parkinson's Telephone"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.OLS(park_train_target, park_train_feat)\nresults = model.fit()\nprint(results.summary())",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.969\nModel:                            OLS   Adj. R-squared:                  0.969\nMethod:                 Least Squares   F-statistic:                     1720.\nDate:                Sat, 04 Apr 2015   Prob (F-statistic):               0.00\nTime:                        14:33:04   Log-Likelihood:                 2051.8\nNo. Observations:                1174   AIC:                            -4062.\nDf Residuals:                    1153   BIC:                            -3955.\nDf Model:                          21                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nx1          5.668e-05      0.000      0.489      0.625        -0.000     0.000\nx2             0.0006      0.000      3.744      0.000         0.000     0.001\nx3             0.0037      0.003      1.094      0.274        -0.003     0.010\nx4          2.015e-05   2.38e-05      0.846      0.398     -2.66e-05  6.69e-05\nx5             0.0018      0.000      3.601      0.000         0.001     0.003\nx6            -0.0009      0.000     -2.267      0.024        -0.002    -0.000\nx7            20.9919      2.275      9.225      0.000        16.527    25.456\nx8           685.5684    124.010      5.528      0.000       442.257   928.880\nx9           -90.5436    456.108     -0.199      0.843      -985.438   804.351\nx10            2.3222      2.024      1.147      0.252        -1.649     6.294\nx11           21.4545    152.086      0.141      0.888      -276.942   319.851\nx12           -1.8458      0.694     -2.658      0.008        -3.208    -0.483\nx13            0.3394      0.050      6.817      0.000         0.242     0.437\nx14         -819.1154    460.794     -1.778      0.076     -1723.205    84.974\nx15           -1.7313      0.659     -2.628      0.009        -3.024    -0.439\nx16            0.7160      0.333      2.153      0.032         0.063     1.369\nx17          272.8101    153.602      1.776      0.076       -28.561   574.181\nx18           -0.4699      0.064     -7.315      0.000        -0.596    -0.344\nx19           -0.0047      0.000    -12.194      0.000        -0.006    -0.004\nx20            0.0912      0.015      5.935      0.000         0.061     0.121\nx21            0.1995      0.017     11.583      0.000         0.166     0.233\n==============================================================================\nOmnibus:                       65.032   Durbin-Watson:                   2.133\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              241.041\nSkew:                          -0.042   Prob(JB):                     4.56e-53\nKurtosis:                       5.218   Cond. No.                     5.00e+07\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large,  5e+07. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n"
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Forest Fires"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.OLS(forest_train_target, forest_train_feat)\nresults = model.fit()\nprint(results.summary())",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.185\nModel:                            OLS   Adj. R-squared:                  0.077\nMethod:                 Least Squares   F-statistic:                     1.717\nDate:                Sat, 04 Apr 2015   Prob (F-statistic):             0.0757\nTime:                        14:33:04   Log-Likelihood:                -504.05\nNo. Observations:                 103   AIC:                             1032.\nDf Residuals:                      91   BIC:                             1064.\nDf Model:                          12                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nx1             2.4792      1.687      1.469      0.145        -0.872     5.831\nx2             1.2008      3.159      0.380      0.705        -5.075     7.476\nx3            -0.1674      0.966     -0.173      0.863        -2.087     1.752\nx4             0.3466      1.817      0.191      0.849        -3.264     3.957\nx5            -0.5377      0.395     -1.361      0.177        -1.323     0.247\nx6            -0.0207      0.079     -0.263      0.793        -0.177     0.135\nx7            -0.0160      0.024     -0.673      0.503        -0.063     0.031\nx8            -0.9087      1.237     -0.734      0.465        -3.367     1.549\nx9             2.1368      0.991      2.157      0.034         0.169     4.105\nx10            0.1941      0.292      0.665      0.508        -0.386     0.774\nx11            2.9129      2.075      1.404      0.164        -1.209     7.035\nx12          -21.9132     22.381     -0.979      0.330       -66.371    22.545\n==============================================================================\nOmnibus:                      148.407   Durbin-Watson:                   2.156\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5490.776\nSkew:                           5.224   Prob(JB):                         0.00\nKurtosis:                      37.209   Cond. No.                     4.22e+03\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 4.22e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n"
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Bayesian Regression"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Yacht Hydrodynamics"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "bls = linear_model.BayesianRidge(compute_score=True)\nbls.fit(yacht_train_feat,yacht_train_target)\nprint \"coefficients\", bls.coef_\nprint \"Correlation coefficient\",bls.score(yacht_test_feat,yacht_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "coefficients [  1.54006401e-03  -6.15970583e-05   2.95637406e-04  -1.29617088e-03\n   5.46114321e-04   1.17615368e-03]\nCorrelation coefficient -0.000665964534197\n"
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Parkinson's Telephone"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "bls = linear_model.BayesianRidge(compute_score=True)\nbls.fit(park_train_feat,park_train_target)\nprint \"coefficients\", bls.coef_\nprint \"Correlation coefficient\",bls.score(park_test_feat,park_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "coefficients [ -3.31450465e-05   2.43932577e-04  -7.18004975e-03   1.95959143e-05\n   1.21717452e-03  -6.17962273e-04   2.22738368e+01   1.53973924e+00\n  -1.86115100e+00   1.29569124e+00  -5.54039256e+00  -9.57766390e-01\n   2.95757742e-01  -2.86402806e-01  -1.84760391e+00   8.78043301e-01\n  -5.84553399e-01  -6.09064269e-01  -8.08045449e-03   6.22705765e-02\n   1.41131015e-01]\nscore 0.708777662509\n"
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Forest Fires"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "bls = linear_model.BayesianRidge(compute_score=True)\nbls.fit(forest_train_feat,forest_train_target)\nprint \"coefficients\", bls.coef_\nprint \"Correlation coefficient\",bls.score(forest_test_feat,forest_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "coefficients [  1.13165054e-04   3.94603479e-05  -5.23484504e-05  -3.21117900e-07\n  -2.23692532e-05   4.76964451e-06  -3.79002098e-03  -3.31505814e-05\n   1.38410726e-04  -5.49910490e-05   1.61898928e-05  -1.12046256e-06]\nscore -0.00469464194026\n"
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Decision Tree Regression"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Yacht Hydrodynamics"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regr = tree.DecisionTreeRegressor()\nregr.fit(yacht_train_feat,yacht_train_target)\nprint \"Correlation coefficient\",regr.score(yacht_test_feat,yacht_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.984266307369\n"
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Parkinson's Telephone"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regr = tree.DecisionTreeRegressor()\nregr.fit(park_train_feat,park_train_target)\nprint \"Correlation coefficient\",regr.score(park_test_feat,park_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.639661435556\n"
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Forest Fires"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regr = tree.DecisionTreeRegressor()\nregr.fit(forest_train_feat,forest_train_target)\nprint \"Correlation coefficient\",regr.score(forest_test_feat,forest_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score -0.295928567935\n"
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Ridge Regression"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Yacht Hydrodynamics"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "rdg = linear_model.RidgeCV()\nrdg.fit(yacht_train_feat,yacht_train_target)\nprint \"coefficients\", rdg.coef_\nprint \"Correlation coefficient\",rdg.score(yacht_test_feat,yacht_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "coefficients [   1.18944185   -1.58698227    4.82198619   -5.93195035  -10.92085527\n  105.6201498 ]\nscore 0.58659780973\n"
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Parkinson's Telephone"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "rdg = linear_model.RidgeCV()\nrdg.fit(park_train_feat,park_train_target)\nprint \"coefficients\", rdg.coef_\nprint \"Correlation coefficient\",rdg.score(park_test_feat,park_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "coefficients [  3.41692310e-05   6.74879463e-04  -1.66961070e-02   3.32077540e-05\n   2.53876841e-03  -1.38421318e-03   7.17489520e-01   5.52582640e-03\n   3.44824325e-01   3.33810623e-01   1.03469933e+00  -2.75418397e-01\n   1.71991753e-01  -1.70449161e-01  -3.22200962e-01  -3.77843933e-02\n  -5.11108279e-01   5.65700576e-02  -8.71964649e-03   1.24101290e-01\n   3.09167604e-01]\nscore 0.694977740317\n"
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Forest Fires"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "rdg = linear_model.RidgeCV()\nrdg.fit(forest_train_feat,forest_train_target)\nprint \"coefficients\", rdg.coef_\nprint \"Correlation coefficient\",rdg.score(forest_test_feat,forest_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "coefficients [ 2.55075799  1.02925435 -0.15697589  0.70725003  0.38232171 -0.02291705\n -0.01936677 -1.29263603  1.90262488  0.1600544   2.57529411 -4.1903259 ]\nscore -0.00884765482445\n"
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Lasso Regression"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Yacht Hydrodynamics"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regr = linear_model.Lasso()\nregr.fit(yacht_train_feat,yacht_train_target)\nprint \"coefficients\", regr.coef_\nprint \"Correlation coefficient\",regr.score(yacht_test_feat,yacht_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "coefficients [  0.38472602  -0.           0.          -0.89183049   0.          23.52332256]\nscore 0.222372346766\n"
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Parkinson's Telephone"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regr = linear_model.Lasso()\nregr.fit(park_train_feat,park_train_target)\nprint \"coefficients\", regr.coef_\nprint \"Correlation coefficient\",regr.score(park_test_feat,park_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "coefficients [ 0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n -0.  0.  0.]\nscore -0.000254920395459\n"
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Forest Fires"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regr = linear_model.Lasso()\nregr.fit(forest_train_feat,forest_train_target)\nprint \"coefficients\", regr.coef_\nprint \"Correlation coefficient\",regr.score(forest_test_feat,forest_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "coefficients [ 2.51650155  0.48753072 -0.05533902  0.34044736  0.         -0.01012053\n -0.02112769 -0.89092857  1.73010745  0.11635921  1.98808573 -0.        ]\nscore -0.00586988539035\n"
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Exponential (Gamma) linear regression"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Yacht Hydrodynamics"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.GLM(yacht_train_target, yacht_train_feat, family=sm.families.Gamma(sm.families.links.identity))\nresults = model.fit()\nprint(results.summary())",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                   61\nModel:                            GLM   Df Residuals:                       55\nModel Family:                   Gamma   Df Model:                            5\nLink Function:               identity   Scale:                  0.983331698661\nMethod:                          IRLS   Log-Likelihood:                -147.31\nDate:                Sat, 04 Apr 2015   Deviance:                       50.261\nTime:                        14:33:10   Pearson chi2:                     54.1\nNo. Iterations:                    51                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nx1             0.5991      0.164      3.650      0.000         0.277     0.921\nx2            -7.5372      1.314     -5.735      0.000       -10.113    -4.961\nx3            -9.8831      1.985     -4.979      0.000       -13.774    -5.993\nx4             3.4332      0.699      4.911      0.000         2.063     4.803\nx5            10.3726      2.129      4.872      0.000         6.200    14.545\nx6            47.9105      6.715      7.135      0.000        34.750    61.071\n==============================================================================\n"
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Parkinson's Telephone"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.GLM(park_train_target, park_train_feat, family=sm.families.Gamma(sm.families.links.identity))\nresults = model.fit()\nprint(results.summary())",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1174\nModel:                            GLM   Df Residuals:                     1153\nModel Family:                   Gamma   Df Model:                           20\nLink Function:               identity   Scale:                  0.036902113529\nMethod:                          IRLS   Log-Likelihood:                 2127.7\nDate:                Sat, 04 Apr 2015   Deviance:                       44.490\nTime:                        14:33:10   Pearson chi2:                     42.5\nNo. Iterations:                    15                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nx1          -5.35e-05   9.73e-05     -0.550      0.582        -0.000     0.000\nx2             0.0006      0.000      4.553      0.000         0.000     0.001\nx3            -0.0030      0.003     -1.126      0.260        -0.008     0.002\nx4         -2.655e-05   1.91e-05     -1.389      0.165      -6.4e-05  1.09e-05\nx5             0.0009      0.000      2.052      0.040      3.97e-05     0.002\nx6            -0.0004      0.000     -1.261      0.207        -0.001     0.000\nx7            33.3900      2.830     11.799      0.000        27.843    38.937\nx8             6.3629    158.679      0.040      0.968      -304.643   317.369\nx9           272.4849    364.433      0.748      0.455      -441.791   986.761\nx10           11.3714      3.169      3.588      0.000         5.160    17.583\nx11         -105.2555    121.518     -0.866      0.386      -343.427   132.916\nx12           -2.4031      0.912     -2.635      0.008        -4.190    -0.616\nx13            0.3128      0.060      5.172      0.000         0.194     0.431\nx14         -502.1636    370.790     -1.354      0.176     -1228.900   224.572\nx15           -2.8555      0.873     -3.271      0.001        -4.567    -1.144\nx16            1.4757      0.431      3.421      0.001         0.630     2.321\nx17          167.6230    123.597      1.356      0.175       -74.623   409.869\nx18           -0.1924      0.085     -2.264      0.024        -0.359    -0.026\nx19           -0.0039      0.000    -12.937      0.000        -0.005    -0.003\nx20            0.0468      0.012      3.745      0.000         0.022     0.071\nx21            0.1921      0.015     12.458      0.000         0.162     0.222\n==============================================================================\n"
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Forest Fires"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.GLM(forest_train_target, forest_train_feat, family=sm.families.Gamma(sm.families.links.identity))\nresults = model.fit()\nprint(results.summary())",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                  103\nModel:                            GLM   Df Residuals:                       91\nModel Family:                   Gamma   Df Model:                           11\nLink Function:               identity   Scale:                     3461189.548\nMethod:                          IRLS   Log-Likelihood:                    nan\nDate:                Sat, 04 Apr 2015   Deviance:                       42160.\nTime:                        14:33:11   Pearson chi2:                 3.15e+08\nNo. Iterations:                   100                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nx1             0.0034      0.140      0.024      0.981        -0.270     0.277\nx2            -0.0006      0.023     -0.024      0.981        -0.046     0.044\nx3             0.0039      0.162      0.024      0.981        -0.313     0.321\nx4             0.0049      0.203      0.024      0.981        -0.393     0.403\nx5            -0.0018      0.075     -0.024      0.981        -0.150     0.146\nx6            -0.0005      0.020     -0.024      0.981        -0.039     0.038\nx7             0.0001      0.005      0.024      0.981        -0.009     0.009\nx8            -0.0014      0.058     -0.024      0.981        -0.115     0.112\nx9             0.0013      0.053      0.024      0.981        -0.102     0.105\nx10            0.0024      0.101      0.024      0.981        -0.196     0.201\nx11           -0.0058      0.240     -0.024      0.981        -0.476     0.464\nx12         1.569e-05      0.001      0.024      0.981        -0.001     0.001\n==============================================================================\n"
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Inverse Gaussian linear regression"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Yacht Hydrodynamics"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.GLM(yacht_train_target, yacht_train_feat, family=sm.families.InverseGaussian(sm.families.links.identity))\nresults = model.fit()\nprint(results.summary())",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                   61\nModel:                            GLM   Df Residuals:                       55\nModel Family:         InverseGaussian   Df Model:                            5\nLink Function:               identity   Scale:                   0.64347752697\nMethod:                          IRLS   Log-Likelihood:                -151.70\nDate:                Sat, 04 Apr 2015   Deviance:                       21.970\nTime:                        14:33:12   Pearson chi2:                     35.4\nNo. Iterations:                    31                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nx1             0.2728      0.100      2.721      0.007         0.076     0.469\nx2            -4.3946      0.731     -6.014      0.000        -5.827    -2.962\nx3            -4.9775      1.196     -4.161      0.000        -7.322    -2.633\nx4             1.7284      0.417      4.142      0.000         0.911     2.546\nx5             5.2843      1.257      4.204      0.000         2.821     7.748\nx6            25.3502      4.847      5.230      0.000        15.850    34.851\n==============================================================================\n"
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Parkinson's Telephone"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.GLM(park_train_target, park_train_feat, family=sm.families.InverseGaussian(sm.families.links.identity))\nresults = model.fit()\nprint(results.summary())",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1174\nModel:                            GLM   Df Residuals:                     1153\nModel Family:         InverseGaussian   Df Model:                           20\nLink Function:               identity   Scale:                  0.199348693397\nMethod:                          IRLS   Log-Likelihood:                 2050.9\nDate:                Sat, 04 Apr 2015   Deviance:                       251.61\nTime:                        14:33:13   Pearson chi2:                     230.\nNo. Iterations:                    16                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nx1          -8.57e-05   8.84e-05     -0.970      0.332        -0.000  8.75e-05\nx2             0.0005      0.000      4.285      0.000         0.000     0.001\nx3            -0.0049      0.002     -2.064      0.039        -0.010    -0.000\nx4         -3.286e-05   1.65e-05     -1.991      0.046     -6.52e-05 -5.13e-07\nx5          9.398e-05      0.000      0.235      0.814        -0.001     0.001\nx6          1.836e-05      0.000      0.057      0.954        -0.001     0.001\nx7            41.7264      3.018     13.828      0.000        35.812    47.641\nx8          -760.5999    183.190     -4.152      0.000     -1119.646  -401.554\nx9           358.3136    314.412      1.140      0.254      -257.922   974.550\nx10           40.4319      3.969     10.187      0.000        32.653    48.211\nx11         -141.9603    104.838     -1.354      0.176      -347.439    63.519\nx12           -2.9776      1.077     -2.766      0.006        -5.088    -0.868\nx13            0.2688      0.065      4.137      0.000         0.141     0.396\nx14          -69.9996    315.857     -0.222      0.825      -689.067   549.068\nx15           -2.0478      0.935     -2.189      0.029        -3.881    -0.215\nx16            1.5808      0.501      3.157      0.002         0.599     2.562\nx17           23.6968    105.281      0.225      0.822      -182.650   230.044\nx18            0.0595      0.106      0.560      0.575        -0.149     0.268\nx19           -0.0031      0.000    -11.418      0.000        -0.004    -0.003\nx20            0.0303      0.011      2.795      0.005         0.009     0.052\nx21            0.1520      0.015     10.023      0.000         0.122     0.182\n==============================================================================\n"
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Forest Fires"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.GLM(forest_train_target, forest_train_feat, family=sm.families.InverseGaussian(sm.families.links.identity))\nresults = model.fit()\nprint(results.summary())",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                  103\nModel:                            GLM   Df Residuals:                       91\nModel Family:         InverseGaussian   Df Model:                           11\nLink Function:               identity   Scale:                   4968436.30372\nMethod:                          IRLS   Log-Likelihood:                    nan\nDate:                Sat, 04 Apr 2015   Deviance:                          inf\nTime:                        14:33:14   Pearson chi2:                 4.52e+08\nNo. Iterations:                     1                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nx1            -0.0646   1610.806  -4.01e-05      1.000     -3157.187  3157.058\nx2             0.3107   3037.773      0.000      1.000     -5953.614  5954.235\nx3            -0.0151    895.641  -1.69e-05      1.000     -1755.439  1755.409\nx4             0.0603   1621.033   3.72e-05      1.000     -3177.107  3177.228\nx5             0.0130    403.252   3.21e-05      1.000      -790.346   790.372\nx6            -0.0032     67.328   -4.7e-05      1.000      -131.965   131.958\nx7             0.0023     22.295      0.000      1.000       -43.694    43.699\nx8            -0.0324   1086.536  -2.98e-05      1.000     -2129.605  2129.540\nx9            -0.0770   1016.791  -7.57e-05      1.000     -1992.951  1992.797\nx10           -0.0175    317.179  -5.53e-05      1.000      -621.677   621.642\nx11            0.0517   1951.683   2.65e-05      1.000     -3825.176  3825.280\nx12            0.4680   1.96e+04   2.39e-05      1.000     -3.84e+04  3.84e+04\n==============================================================================\n"
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Support Vector Machine"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Breast Cancer"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = svm.SVC()\nclf.fit(breast_train_feat,breast_train_target)\nprint \"score\", clf.score(breast_test_feat,breast_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.95\n"
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Optical character recognition"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = svm.SVC()\nclf.fit(optical_train_feat,optical_train_target)\nprint \"score\", clf.score(optical_test_feat,optical_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score "
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0.218861209964\n"
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Bank note"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = svm.SVC()\nclf.fit(bank_train_feat,bank_train_target)\nprint \"score\", clf.score(bank_test_feat,bank_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.986338797814\n"
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Climate model"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = svm.SVC()\nclf.fit(climate_train_feat,climate_train_target)\nprint \"score\", clf.score(climate_test_feat,climate_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.921296296296\n"
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Ecoli"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = svm.SVC()\nclf.fit(ecoli_train_feat,ecoli_train_target)\nprint \"score\", clf.score(ecoli_test_feat,ecoli_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.64312267658\n"
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Decision Tree"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Breast Cancer"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = tree.DecisionTreeClassifier()\nclf.fit(breast_train_feat,breast_train_target)\nprint \"score\", clf.score(breast_test_feat,breast_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.944642857143\n"
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Optical character recognition"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = tree.DecisionTreeClassifier()\nclf.fit(optical_train_feat,optical_train_target)\nprint \"score\", clf.score(optical_test_feat,optical_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.844973309609\n"
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Bank Note"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = tree.DecisionTreeClassifier()\nclf.fit(bank_train_feat,bank_train_target)\nprint \"score\", clf.score(bank_test_feat,bank_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.944444444444\n"
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Climate Model"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = tree.DecisionTreeClassifier()\nclf.fit(climate_train_feat,climate_train_target)\nprint \"score\", clf.score(climate_test_feat,climate_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.923611111111\n"
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Ecoli"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = tree.DecisionTreeClassifier()\nclf.fit(ecoli_train_feat,ecoli_train_target)\nprint \"score\", clf.score(ecoli_test_feat,ecoli_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.769516728625\n"
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Fisher Linear Discriminant "
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Breast Cancer"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = LDA()\nclf.fit(breast_train_feat,breast_train_target)\nprint \"score\", clf.score(breast_test_feat,breast_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.960714285714\n"
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Optical character recognition"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = LDA()\nclf.fit(optical_train_feat,optical_train_target)\nprint \"score\", clf.score(optical_test_feat,optical_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.944172597865\n"
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": "/usr/lib/python2.7/dist-packages/sklearn/lda.py:162: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Bank Note"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = LDA()\nclf.fit(bank_train_feat,bank_train_target)\nprint \"score\", clf.score(bank_test_feat,bank_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.969034608379\n"
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Climate Model"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = LDA()\nclf.fit(climate_train_feat,climate_train_target)\nprint \"score\", clf.score(climate_test_feat,climate_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.884259259259\n"
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Ecoli"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = LDA()\nclf.fit(ecoli_train_feat,ecoli_train_target)\nprint \"score\", clf.score(ecoli_test_feat,ecoli_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.828996282528\n"
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Logistic Regression"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Breast Cancer"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = linear_model.LogisticRegression()\nclf.fit(breast_train_feat,breast_train_target)\nprint \"score\", clf.score(breast_test_feat,breast_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.957142857143\n"
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Optical character recognition"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = linear_model.LogisticRegression()\nclf.fit(optical_train_feat,optical_train_target)\nprint \"score\", clf.score(optical_test_feat,optical_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.953291814947\n"
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Bank Note"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = linear_model.LogisticRegression()\nclf.fit(bank_train_feat,bank_train_target)\nprint \"score\", clf.score(bank_test_feat,bank_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.982695810565\n"
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Climate Model"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = linear_model.LogisticRegression()\nclf.fit(climate_train_feat,climate_train_target)\nprint \"score\", clf.score(climate_test_feat,climate_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.925925925926\n"
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Ecoli"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = linear_model.LogisticRegression()\nclf.fit(ecoli_train_feat,ecoli_train_target)\nprint \"score\", clf.score(ecoli_test_feat,ecoli_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.736059479554\n"
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Nearest Neighbors"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Breast Cancer"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = neighbors.KNeighborsClassifier()\nclf.fit(breast_train_feat,breast_train_target)\nprint \"score\", clf.score(breast_test_feat,breast_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.966071428571\n"
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Optical character recognition"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = neighbors.KNeighborsClassifier()\nclf.fit(optical_train_feat,optical_train_target)\nprint \"score\", clf.score(optical_test_feat,optical_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score "
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0.971975088968\n"
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Bank Note"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = neighbors.KNeighborsClassifier()\nclf.fit(bank_train_feat,bank_train_target)\nprint \"score\", clf.score(bank_test_feat,bank_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.98087431694\n"
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Climate Model"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = neighbors.KNeighborsClassifier()\nclf.fit(climate_train_feat,climate_train_target)\nprint \"score\", clf.score(climate_test_feat,climate_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.921296296296\n"
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Ecoli"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = linear_model.LogisticRegression()\nclf.fit(ecoli_train_feat,ecoli_train_target)\nprint \"score\", clf.score(ecoli_test_feat,ecoli_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.736059479554\n"
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Naive Bayes "
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Breast Cancer"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = GaussianNB()\nclf.fit(breast_train_feat,breast_train_target)\nprint \"score\", clf.score(breast_test_feat,breast_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.948214285714\n"
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Optical Character Recognition"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = GaussianNB()\nclf.fit(optical_train_feat,optical_train_target)\nprint \"score\", clf.score(optical_test_feat,optical_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.778024911032\n"
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Bank Note"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = GaussianNB()\nclf.fit(bank_train_feat,bank_train_target)\nprint \"score\", clf.score(bank_test_feat,bank_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.87795992714\n"
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Climate Model"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = GaussianNB()\nclf.fit(climate_train_feat,climate_train_target)\nprint \"score\", clf.score(climate_test_feat,climate_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.930555555556\n"
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Ecoli"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = GaussianNB()\nclf.fit(ecoli_train_feat,ecoli_train_target)\nprint \"score\", clf.score(ecoli_test_feat,ecoli_test_target)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "score 0.788104089219\n"
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}